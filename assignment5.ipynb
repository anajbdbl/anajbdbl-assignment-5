{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74KsjjceC2C8",
        "outputId": "44f42a80-ade3-4aa7-a4f4-e6efbf114126"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "csLVbI13C2C_"
      },
      "outputs": [],
      "source": [
        "# Define the KNN class\n",
        "class KNN:\n",
        "    def __init__(self, k=3, distance_metric='euclidean'):\n",
        "        self.k = k\n",
        "        self.distance_metric = distance_metric\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # TODO: Implement the fit method\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def predict(self, X):\n",
        "        # TODO: Implement the predict method\n",
        "        predictions = [self._predict_single(x) for x in X]\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def _predict_single(self, x):\n",
        "        # Predict the class of a single sample.\n",
        "        distances = self.compute_distance(self.X_train, x)\n",
        "        k_nearest_indices = np.argsort(distances)[:self.k]\n",
        "        k_nearest_labels = self.y_train[k_nearest_indices]\n",
        "        return np.mean(k_nearest_labels == 1)\n",
        "\n",
        "    def compute_distance(self, X1, X2):\n",
        "        # TODO: Implement distance computation based on self.distance_metric\n",
        "        # Hint: Use numpy operations for efficient computation\n",
        "        if self.distance_metric == 'euclidean':\n",
        "            return np.sqrt(np.sum((X1 - X2) ** 2, axis=1))\n",
        "        elif self.distance_metric == 'manhattan':\n",
        "            return np.sum(np.abs(X1 - X2), axis=1)\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported distance metric\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "4p6gK42XC2DA"
      },
      "outputs": [],
      "source": [
        "# Define data preprocessing function\n",
        "def preprocess_data(train_path, test_path):\n",
        "    train_data = pd.read_csv(train_path)\n",
        "    test_data = pd.read_csv(test_path)\n",
        "\n",
        "    # TODO: Implement data preprocessing\n",
        "    # Handle categorical variables, scale features, etc.\n",
        "\n",
        "    # Drop unnecessary columns\n",
        "    train_data = train_data.drop(columns=['CustomerId', 'Surname'])\n",
        "    test_data = test_data.drop(columns=['CustomerId', 'Surname'])\n",
        "\n",
        "    # Encode categorical variables\n",
        "    # Gender encoding\n",
        "    train_data['Gender'] = (train_data['Gender'] == 'Male').astype(int)\n",
        "    test_data['Gender'] = (test_data['Gender'] == 'Male').astype(int)\n",
        "\n",
        "    # One-hot encoding for 'Geography'\n",
        "    train_data = pd.get_dummies(train_data, columns=['Geography'], drop_first=True)\n",
        "    test_data = pd.get_dummies(test_data, columns=['Geography'], drop_first=True)\n",
        "\n",
        "    # Ensure test set has the same columns as the train set\n",
        "    missing_cols = set(train_data.columns) - set(test_data.columns)\n",
        "    for col in missing_cols:\n",
        "        test_data[col] = 0\n",
        "    test_data = test_data[train_data.columns.drop('Exited')]\n",
        "\n",
        "    # Extract labels from train data\n",
        "    y = train_data['Exited']\n",
        "    X = train_data.drop(columns=['Exited'])\n",
        "    X_test = test_data  # Now X_test is properly defined\n",
        "\n",
        "    # Scale features manually (mean normalization)\n",
        "    X_train_mean = X.mean()\n",
        "    X_train_std = X.std()\n",
        "\n",
        "    X = (X - X_train_mean) / X_train_std\n",
        "    X_test = (X_test - X_train_mean) / X_train_std  # Use train mean and std for test data\n",
        "\n",
        "    return X.values, y.values, X_test.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "2EvRdqCkC2DA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define cross-validation function\n",
        "def cross_validate(X, y, knn, n_splits=10):\n",
        "    # TODO: Implement cross-validation\n",
        "    # Compute ROC AUC scores\n",
        "    fold_size = len(X) // n_splits\n",
        "    roc_auc_scores = []\n",
        "\n",
        "    for i in range(n_splits):\n",
        "        # Split the data into training and validation sets\n",
        "        X_val = X[i * fold_size:(i + 1) * fold_size]\n",
        "        y_val = y[i * fold_size:(i + 1) * fold_size]\n",
        "\n",
        "        X_train = np.concatenate([X[:i * fold_size], X[(i + 1) * fold_size:]])\n",
        "        y_train = np.concatenate([y[:i * fold_size], y[(i + 1) * fold_size:]])\n",
        "\n",
        "        # Fit the KNN model and make predictions\n",
        "        knn.fit(X_train, y_train)\n",
        "        y_pred = knn.predict(X_val)\n",
        "\n",
        "        # Calculate ROC-AUC score and store it\n",
        "        roc_auc = compute_roc_auc(y_val, y_pred)\n",
        "        roc_auc_scores.append(roc_auc)\n",
        "\n",
        "    return np.mean(roc_auc_scores)\n",
        "\n",
        "def compute_roc_auc(y_true, y_pred):\n",
        "    sorted_indices = np.argsort(y_pred)[::-1]  # Sort by predicted probabilities\n",
        "    y_true = y_true[sorted_indices]\n",
        "    cumulative_positive = np.cumsum(y_true)\n",
        "    total_positive = np.sum(y_true)\n",
        "    total_negative = len(y_true) - total_positive\n",
        "\n",
        "    tpr = cumulative_positive / total_positive  # True Positive Rate\n",
        "    fpr = (np.arange(len(y_true)) + 1 - cumulative_positive) / total_negative  # False Positive Rate\n",
        "\n",
        "    return np.trapz(tpr, fpr)  # Area under the ROC curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgc56ZCuC2DA",
        "outputId": "797c52e9-9080-41ba-e6ad-3031d05319a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: 0.8671167290574422\n",
            "ROC-AUC Score with k=1, metric=euclidean: 0.7516\n",
            "ROC-AUC Score with k=3, metric=euclidean: 0.8417\n",
            "ROC-AUC Score with k=5, metric=euclidean: 0.8671\n",
            "ROC-AUC Score with k=7, metric=euclidean: 0.8811\n",
            "ROC-AUC Score with k=9, metric=euclidean: 0.8880\n",
            "ROC-AUC Score with k=11, metric=euclidean: 0.8901\n",
            "ROC-AUC Score with k=13, metric=euclidean: 0.8942\n",
            "ROC-AUC Score with k=15, metric=euclidean: 0.8946\n",
            "ROC-AUC Score with k=17, metric=euclidean: 0.8969\n",
            "ROC-AUC Score with k=19, metric=euclidean: 0.8986\n",
            "ROC-AUC Score with k=1, metric=manhattan: 0.7558\n",
            "ROC-AUC Score with k=3, metric=manhattan: 0.8459\n",
            "ROC-AUC Score with k=5, metric=manhattan: 0.8695\n",
            "ROC-AUC Score with k=7, metric=manhattan: 0.8810\n",
            "ROC-AUC Score with k=9, metric=manhattan: 0.8885\n",
            "ROC-AUC Score with k=11, metric=manhattan: 0.8930\n",
            "ROC-AUC Score with k=13, metric=manhattan: 0.8961\n",
            "ROC-AUC Score with k=15, metric=manhattan: 0.8983\n",
            "ROC-AUC Score with k=17, metric=manhattan: 0.8997\n",
            "ROC-AUC Score with k=19, metric=manhattan: 0.9006\n",
            "Best k: 19, Best metric: manhattan with ROC-AUC Score: 0.9006\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess data\n",
        "X, y, X_test = preprocess_data('/content/drive/MyDrive/CS506/Assignment5/train.csv', '/content/drive/MyDrive/CS506/Assignment5/test.csv')\n",
        "\n",
        "# Create and evaluate model\n",
        "knn = KNN(k=5, distance_metric='euclidean')\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_validate(X, y, knn)\n",
        "\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "\n",
        "# TODO: hyperparamters tuning\n",
        "best_k = 1\n",
        "best_score = 0\n",
        "best_metric = 'euclidean'\n",
        "\n",
        "for metric in ['euclidean', 'manhattan']:\n",
        "    for k in range(1, 21, 2):\n",
        "        knn = KNN(k=k, distance_metric=metric)\n",
        "        score = cross_validate(X, y, knn)\n",
        "        print(f\"ROC-AUC Score with k={k}, metric={metric}: {score:.4f}\")\n",
        "\n",
        "        if score > best_score:\n",
        "            best_k = k\n",
        "            best_metric = metric\n",
        "            best_score = score\n",
        "\n",
        "print(f\"Best k: {best_k}, Best metric: {best_metric} with ROC-AUC Score: {best_score:.4f}\")\n",
        "\n",
        "# TODO: Train on full dataset with optimal hyperparameters and make predictions on test set\n",
        "knn = KNN(k=best_k, distance_metric=best_metric)\n",
        "knn.fit(X, y)\n",
        "test_predictions = knn.predict(X_test)\n",
        "\n",
        "# Save test predictions\n",
        "pd.DataFrame({'id': pd.read_csv('/content/drive/MyDrive/CS506/Assignment5/test.csv')['id'], 'Exited': test_predictions}).to_csv('/content/drive/MyDrive/CS506/Assignment5/submissions.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "cs506",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}